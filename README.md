## 1. Predator-Prey Simulation
- Simulation of predators trying to catch prey using cooperative strategy.


This code: 
âœ… Implements cooperative predators
âœ… Uses Manhattan distance for pathfinding
âœ… Uses communication between predators
âœ… Real-time updates with matplotlib

ğŸ” Features Added:
âœ… Cooperative behavior for predators
âœ… Prey attempts to evade capture strategically
âœ… Real-time updates and visualization
âœ… Dynamic pathfinding using Manhattan distance
âœ… Event-based termination (capture or survival)

### How to Run
python multi-agent-predator-prey/predator_prey.py


## 2. Predator-Prey with Q-Learning
- Multi-agent reinforcement learning using Q-Learning for predator-prey simulation.

ğŸ”¥ Why RL?
âœ… Reinforcement Learning allows agents to learn from experience instead of relying on pre-coded strategies.
âœ… It introduces dynamic, adaptive behavior as agents improve based on feedback.
âœ… Multi-Agent RL (MARL) is a hot field in robotics, game AI, and autonomous systems.

ğŸ† New Features to Add:
âœ… Q-Learning for decision-making (agents learn from rewards and penalties).
âœ… Shared state for cooperative learning among predators.
âœ… Exploration vs. Exploitation â€“ Encourage agents to explore the environment early and exploit learned knowledge later.
âœ… Custom Reward System â€“ Reward successful capture, penalize collisions.
âœ… Training Phase â€“ Run a training loop for agents to learn better strategies over time.

### How to Run
python multi-agent-rl/predator_prey_qlearning.py

## 3. Advanced Multi-Agent Predator-Prey Simulation with DQN
- Multi-agent system using Deep Q-Learning (DQN) with communication, flocking, and adaptive prey behavior.

âœ… Why SARSA?
SARSA considers the next action in the update equation, leading to more stable learning.
SARSA handles stochastic environments better than Q-Learning.

âœ… Why DQN?
Handle larger state-action spaces using neural networks.
Handle continuous state spaces better than tabular methods.

âœ… Why Flocking?
Flocking creates realistic behavior based on three rules:
Alignment â€“ Move in the same direction as nearby agents.
Cohesion â€“ Move toward the average position of nearby agents.
Separation â€“ Avoid getting too close to other agents.

âœ… Why Adaptive Prey?
Make prey smarter by using pathfinding and grouping.
Prey can also learn using SARSA or DQN.

âœ… Why Team Rewards?
Encourage cooperation over selfish behavior.
Higher reward when multiple predators contribute to catching prey.

### How to Run
python multi-agent-dqn/multi_agent_predator_prey_dqn.py